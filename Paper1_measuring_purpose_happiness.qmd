---
title: "Measuring Purpose and Happiness"
subtitle: "Psychometrics and Tests of Stability and Specificity Over Two Years"
author: 
  - name: Patrick E. McKnight
    orcid: 0000-0002-9067-9066
    email: pmcknigh@gmu.edu
    affiliation: 
      name: George Mason University
      department: Department of Psychology
    role: "corresponding author"
  - name: Todd B. Kashdan
    orcid: 0000-0001-6438-0485
    email: tkashdan@gmu.edu
    affiliation: 
      name: George Mason University
      department: Department of Psychology
    role: "corresponding author"
  - name: Amie MacKay
    affiliation:
      name: George Mason University
      department: Department of Psychology
format: 
  html:
    toc: true
    code-fold: true
  pdf:
   toc: true
   colorlinks: true
  docx:
   reference_docx: "apa6.docx"
   toc: true
   fig_width: 6
   fig_height: 4
   fig_caption: true
   number_sections: true
   highlight: tango
prefer-html: true

bibliography: references.bib
abstract: In the social sciences, a case has been made for distinguishing between purpose in life and happiness. That said, a surprisingly small number of direct empirical comparisons exist. The following study addresses the relative stability of purpose and happiness ratings over time (baseline, 6 months, and 1 year follow-up). In addition, we explored whether purpose and happiness change independently of each other over time. Furthermore, we tested what best differentiates purpose and happiness using a comprehensive battery of personality constructs (e.g., goal-specific hope scale, psychological needs, distress tolerance, and values). 
keywords: 
  - purpose in life
  - happiness
  - life satisfaction
  - well-being
  - values
  - personality
---


# Analysis 1:  Descriptives and Psychometrics (Comparability of Measures)

```{r}
#| echo: false
#| message: false
#| error: false

# Load required packages
library(psych)   # For reliability analysis
library(dplyr)
library(knitr)   # For table formatting
library(kableExtra) # For enhanced tables
library(tidyr)

# Read the data
data <- read.csv("tmpPvHitems4LLM.csv")

# Calculate POMP scores using a simpler approach: (mean score × 100) / maximum possible score
# Define the maximum possible scores
happiness_max <- 7  # Maximum score of 7 for happiness items
purpose_max <- 5    # Maximum score of 5 for purpose items

# Define the item groups
happiness_items <- list(
  baseline = c("b_shs_gh_a", "b_shs_rh_a", "b_shs_ch_a", "b_shs_ch_b_r"),
  follow_up1 = c("fu1_shs_gh_a", "fu1_shs_rh_a", "fu1_shs_ch_a", "fu1_shs_ch_fu1_r"),
  follow_up2 = c("fu2_shs_gh_a", "fu2_shs_rh_a", "fu2_shs_ch_a", "fu2_shs_ch_b_r")
)

purpose_items <- list(
  baseline = c("b_bpurp_1", "b_bpurp_2", "b_bpurp_3", "b_bpurp_4"),
  follow_up1 = c("fu1_bpurp_1", "fu1_bpurp_2", "fu1_bpurp_3", "fu1_bpurp_4"),
  follow_up2 = c("fu2_bpurp_1", "fu2_bpurp_2", "fu2_bpurp_3", "fu2_bpurp_4")
)

# Calculate POMP scores directly and store in a structured format
results <- data.frame(
  Measure = character(),
  Timepoint = character(),
  N = numeric(),
  Mean = numeric(),
  SD = numeric(),
  Min = numeric(),
  Max = numeric(),
  Alpha = numeric(),
  stringsAsFactors = FALSE
)

# Process happiness measures
for (tp_name in names(happiness_items)) {
  # Get display name for timepoint
  display_name <- switch(tp_name,
                         "baseline" = "Baseline",
                         "follow_up1" = "Follow-up 1",
                         "follow_up2" = "Follow-up 2")
  
  # Get items for this timepoint
  items <- happiness_items[[tp_name]]
  
  # Calculate alpha reliability
  alpha_result <- psych::alpha(data[, items], check.keys = TRUE)
  
  # Calculate POMP scores
  pomp_scores <- rowMeans(data[, items], na.rm = TRUE) * 100 / happiness_max
  
  # Calculate statistics
  n_valid <- sum(!is.na(pomp_scores))
  mean_val <- mean(pomp_scores, na.rm = TRUE)
  sd_val <- sd(pomp_scores, na.rm = TRUE)
  min_val <- min(pomp_scores, na.rm = TRUE)
  max_val <- max(pomp_scores, na.rm = TRUE)
  
  # Add to results
  results <- rbind(results, data.frame(
    Measure = "Happiness",
    Timepoint = display_name,
    N = n_valid,
    Mean = mean_val,
    SD = sd_val,
    Min = min_val,
    Max = max_val,
    Alpha = alpha_result$total$raw_alpha
  ))
}

# Process purpose measures
for (tp_name in names(purpose_items)) {
  # Get display name for timepoint
  display_name <- switch(tp_name,
                         "baseline" = "Baseline",
                         "follow_up1" = "Follow-up 1",
                         "follow_up2" = "Follow-up 2")
  
  # Get items for this timepoint
  items <- purpose_items[[tp_name]]
  
  # Calculate alpha reliability
  alpha_result <- psych::alpha(data[, items], check.keys = TRUE)
  
  # Calculate POMP scores
  pomp_scores <- rowMeans(data[, items], na.rm = TRUE) * 100 / purpose_max
  
  # Calculate statistics
  n_valid <- sum(!is.na(pomp_scores))
  mean_val <- mean(pomp_scores, na.rm = TRUE)
  sd_val <- sd(pomp_scores, na.rm = TRUE)
  min_val <- min(pomp_scores, na.rm = TRUE)
  max_val <- max(pomp_scores, na.rm = TRUE)
  
  # Add to results
  results <- rbind(results, data.frame(
    Measure = "Purpose",
    Timepoint = display_name,
    N = n_valid,
    Mean = mean_val,
    SD = sd_val,
    Min = min_val,
    Max = max_val,
    Alpha = alpha_result$total$raw_alpha
  ))
}

# Format the numeric columns to have consistent decimal places
results$Mean <- sprintf("%.2f", results$Mean)
results$SD <- sprintf("%.2f", results$SD)
results$Min <- sprintf("%.2f", results$Min)
results$Max <- sprintf("%.2f", results$Max)
results$Alpha <- sprintf("%.3f", results$Alpha)  # Use 3 decimal places for alpha

# Create the final formatted table
final_table <- kable(results, 
                   format = "html", 
                   caption = "Table 1. Psychometric Properties of Happiness and Purpose Measures Across Timepoints (POMP Scores)",
                   row.names = FALSE,
                   col.names = c("Measure", "Timepoint", "N", "Mean", "SD", "Min", "Max", "Cronbach's α")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
              full_width = FALSE) %>%
  row_spec(0, bold = TRUE)

# Function to export tables to CSV
export_tables <- function() {
  write.csv(results, "psychometric_properties.csv", row.names = FALSE)
  cat("Table exported to CSV file.\n")
}

final_table




```

# Analysis 2:  Multi-Sample Analysis (Temporal Stability of Relationship)

```{r}
#| echo: false
#| message: false
#| error: false

# Complete Multisample CFA Analysis of Purpose and Happiness
# This script performs a multisample CFA on the relationship between 
# Purpose and Happiness across three timepoints.

# Load required packages
library(lavaan)       # For CFA analysis
library(dplyr)        # For data manipulation
library(tidyr)        # For data reshaping
library(psych)        # For descriptive statistics
library(semPlot)      # For path diagrams
library(ggplot2)      # For visualization
library(gridExtra)    # For arranging plots
library(knitr)        # For table formatting
library(kableExtra)   # For enhanced tables

# 1. Read the data
data <- read.csv("tmpPvHitems4LLM.csv")

# 2. Define maximum scores for POMP calculation
happiness_max <- 7  # Maximum score for happiness items
purpose_max <- 5    # Maximum score for purpose items

# 3. Define the item groups (same as in the CTT analysis)
happiness_items <- list(
  baseline = c("b_shs_gh_a", "b_shs_rh_a", "b_shs_ch_a", "b_shs_ch_b_r"),
  follow_up1 = c("fu1_shs_gh_a", "fu1_shs_rh_a", "fu1_shs_ch_a", "fu1_shs_ch_fu1_r"),
  follow_up2 = c("fu2_shs_gh_a", "fu2_shs_rh_a", "fu2_shs_ch_a", "fu2_shs_ch_b_r")
)

purpose_items <- list(
  baseline = c("b_bpurp_1", "b_bpurp_2", "b_bpurp_3", "b_bpurp_4"),
  follow_up1 = c("fu1_bpurp_1", "fu1_bpurp_2", "fu1_bpurp_3", "fu1_bpurp_4"),
  follow_up2 = c("fu2_bpurp_1", "fu2_bpurp_2", "fu2_bpurp_3", "fu2_bpurp_4")
)

# 4. Check missing data patterns
cat("Missing data summary:\n")
all_items <- c(unlist(happiness_items), unlist(purpose_items))
missing_counts <- colSums(is.na(data[, all_items]))
print(missing_counts)

# 5. Convert data to POMP scores
# For Happiness items (scale 0-7)
for (item in unlist(happiness_items)) {
  data[[paste0(item, "_pomp")]] <- data[[item]] * 100 / happiness_max
}

# For Purpose items (scale 0-5)
for (item in unlist(purpose_items)) {
  data[[paste0(item, "_pomp")]] <- data[[item]] * 100 / purpose_max
}

# 6. Descriptive statistics for POMP scores
happiness_pomp_items <- paste0(unlist(happiness_items), "_pomp")
purpose_pomp_items <- paste0(unlist(purpose_items), "_pomp")

cat("\nDescriptive statistics for POMP scores:\n")
describe(data[, c(happiness_pomp_items, purpose_pomp_items)], fast = TRUE)

# 7. Define the CFA model
cfa_model <- '
  # Baseline measurement model
  baseline_happiness =~ b_shs_gh_a_pomp + b_shs_rh_a_pomp + b_shs_ch_a_pomp + b_shs_ch_b_r_pomp
  baseline_purpose =~ b_bpurp_1_pomp + b_bpurp_2_pomp + b_bpurp_3_pomp + b_bpurp_4_pomp
  
  # Follow-up 1 measurement model
  followup1_happiness =~ fu1_shs_gh_a_pomp + fu1_shs_rh_a_pomp + fu1_shs_ch_a_pomp + fu1_shs_ch_fu1_r_pomp
  followup1_purpose =~ fu1_bpurp_1_pomp + fu1_bpurp_2_pomp + fu1_bpurp_3_pomp + fu1_bpurp_4_pomp
  
  # Follow-up 2 measurement model
  followup2_happiness =~ fu2_shs_gh_a_pomp + fu2_shs_rh_a_pomp + fu2_shs_ch_a_pomp + fu2_shs_ch_b_r_pomp
  followup2_purpose =~ fu2_bpurp_1_pomp + fu2_bpurp_2_pomp + fu2_bpurp_3_pomp + fu2_bpurp_4_pomp
  
  # Correlations between constructs within each timepoint
  baseline_happiness ~~ baseline_purpose
  followup1_happiness ~~ followup1_purpose
  followup2_happiness ~~ followup2_purpose
'

# 8. Fit the CFA model using FIML for handling missing data
cat("\nFitting multisample CFA model with FIML...\n")
cfa_fit <- cfa(cfa_model, 
               data = data, 
               std.lv = TRUE,          # Standardize latent variables
               missing = "fiml",       # Use FIML for missing data
               estimator = "ML")       # Maximum likelihood estimation

# 9. Print model fit indices
cat("\nModel Fit Indices:\n")
fit_indices <- fitMeasures(cfa_fit, c("chisq", "df", "pvalue", "cfi", "tli", "rmsea", "srmr", "aic", "bic"))
print(fit_indices)

# 10. Extract factor loadings
loadings <- standardizedSolution(cfa_fit) %>%
  filter(op == "=~") %>%
  select(lhs, rhs, est.std, pvalue)
cat("\nStandardized Factor Loadings:\n")
print(loadings)

# 11. Extract standardized correlations between latent variables
correlations <- standardizedSolution(cfa_fit) %>%
  filter(op == "~~", 
         grepl("happiness", lhs), 
         grepl("purpose", rhs)) %>%
  select(lhs, rhs, est.std, pvalue)

cat("\nStandardized Correlations between Purpose and Happiness:\n")
correlations_table <- data.frame(
  Timepoint = c("Baseline", "Follow-up 1", "Follow-up 2"),
  Correlation = sprintf("%.3f", correlations$est.std),
  p_value = sprintf("%.3f", correlations$pvalue)
)
print(correlations_table)

# 12. Create a nice table for reporting
formatted_table <- kable(correlations_table,
                       format = "html",
                       caption = "Table 1. Standardized Correlations Between Purpose and Happiness (POMP Scores)",
                       col.names = c("Timepoint", "Correlation (r)", "p-value")) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
              full_width = FALSE) %>%
  row_spec(0, bold = TRUE)

cat("\nFormatted Table created as formatted_table\n")

# 13. Create a structural diagram showing the relationship
# Create a ggplot2 visualization
plot_data <- data.frame(
  x = rep(c(1, 3), 3),
  y = rep(c(1, 1, 2, 2, 3, 3), each = 1),
  group = rep(c("Happiness", "Purpose"), 3),
  timepoint = rep(c("Baseline", "Follow-up 1", "Follow-up 2"), each = 2)
)

# Create the plot
p <- ggplot(plot_data, aes(x = x, y = y)) +
  # Add shapes for the constructs
  geom_point(aes(color = group), size = 30, alpha = 0.3) +
  # Add labels for the constructs
  geom_text(aes(label = group), size = 4, fontface = "bold") +
  # Add timepoint labels
  geom_text(data = data.frame(x = 0.4, y = c(1, 2, 3), 
                            label = c("Baseline", "Follow-up 1", "Follow-up 2")),
          aes(x = x, y = y, label = label), size = 4, hjust = 0, fontface = "bold") +
  # Add correlation arrows and values
  geom_segment(data = data.frame(y = c(1, 2, 3), 
                               correlation = correlations$est.std),
             aes(x = 1.3, xend = 2.7, y = y, yend = y),
             arrow = arrow(ends = "both", type = "open", length = unit(0.2, "cm")),
             size = 0.7) +
  geom_text(data = data.frame(y = c(1, 2, 3), 
                             correlation = sprintf("r = %.3f", correlations$est.std)),
           aes(x = 2, y = y + 0.2, label = correlation), size = 3.5) +
  # Add titles and customize theme
  labs(title = "Structural Relationship Between Purpose and Happiness",
       subtitle = "Standardized Correlations by Timepoint (POMP Scores)") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    panel.grid = element_blank(),
    axis.text = element_blank(),
    axis.title = element_blank(),
    legend.position = "none"
  ) +
  scale_color_manual(values = c("Happiness" = "skyblue", "Purpose" = "lightgreen")) +
  xlim(0, 4) + ylim(0.5, 3.5)

# Save the plot
ggsave("purpose_happiness_relationship.png", p, width = 8, height = 6, dpi = 300)
cat("\nVisualization saved as 'purpose_happiness_relationship.png'\n")

# 14. Create a more detailed path diagram using semPlot
try({
  semplot_file <- "cfa_model_diagram.pdf"
  semPaths(cfa_fit, 
           what = "std", 
           edge.label.cex = 0.6,
           sizeMan = 5,
           style = "ram",
           layout = "tree2",
           edge.color = "black",
           nCharNodes = 0,
           nodeLabels = c("Happiness\nBaseline", "Purpose\nBaseline", 
                          "Happiness\nFollow-up 1", "Purpose\nFollow-up 1", 
                          "Happiness\nFollow-up 2", "Purpose\nFollow-up 2", 
                          "SHS1\nB", "SHS2\nB", "SHS3\nB", "SHS4\nB",
                          "PURP1\nB", "PURP2\nB", "PURP3\nB", "PURP4\nB",
                          "SHS1\nFU1", "SHS2\nFU1", "SHS3\nFU1", "SHS4\nFU1",
                          "PURP1\nFU1", "PURP2\nFU1", "PURP3\nFU1", "PURP4\nFU1",
                          "SHS1\nFU2", "SHS2\nFU2", "SHS3\nFU2", "SHS4\nFU2",
                          "PURP1\nFU2", "PURP2\nFU2", "PURP3\nFU2", "PURP4\nFU2"),
           groups = list(latents = c(1:6), 
                         manifest = c(7:30)),
           color = list(latents = c("lightblue"), 
                        manifest = c("lightyellow")),
           label.scale = FALSE,
           residuals = FALSE,
           title = FALSE)
  
  # Save to PDF separately
  dev.copy2pdf(file = semplot_file)
  cat(paste0("\nDetailed CFA path diagram saved as '", semplot_file, "'\n"))
}, silent = FALSE)

# Alternative approach if the above still causes issues
try({
  cat("\nAttempting alternative approach for creating semPlot diagram...\n")
  pdf("cfa_model_diagram_alt.pdf", width = 10, height = 8)
  semPaths(cfa_fit, 
           what = "std", 
           edge.label.cex = 0.6,
           sizeMan = 5,
           style = "ram",
           layout = "tree2",
           edge.color = "black",
           nCharNodes = 0,
           nodeLabels = c("Happiness\nBaseline", "Purpose\nBaseline", 
                          "Happiness\nFollow-up 1", "Purpose\nFollow-up 1", 
                          "Happiness\nFollow-up 2", "Purpose\nFollow-up 2", 
                          "SHS1\nB", "SHS2\nB", "SHS3\nB", "SHS4\nB",
                          "PURP1\nB", "PURP2\nB", "PURP3\nB", "PURP4\nB",
                          "SHS1\nFU1", "SHS2\nFU1", "SHS3\nFU1", "SHS4\nFU1",
                          "PURP1\nFU1", "PURP2\nFU1", "PURP3\nFU1", "PURP4\nFU1",
                          "SHS1\nFU2", "SHS2\nFU2", "SHS3\nFU2", "SHS4\nFU2",
                          "PURP1\nFU2", "PURP2\nFU2", "PURP3\nFU2", "PURP4\nFU2"),
           groups = list(latents = c(1:6), 
                         manifest = c(7:30)),
           color = list(latents = c("lightblue"), 
                        manifest = c("lightyellow")),
           label.scale = FALSE,
           residuals = FALSE,
           title = FALSE)
  dev.off()
  cat("\nAlternative CFA path diagram saved as 'cfa_model_diagram_alt.pdf'\n")
}, silent = FALSE)

cat(paste0("\nDetailed CFA path diagram saved as '", semplot_file, "'\n"))

# 15. Report model summary and interpretation
cat("\n====== MULTISAMPLE CFA RESULTS SUMMARY ======\n")
cat("\nThe multisample CFA model examined the structural relationship between Purpose and Happiness")
cat("\nacross three timepoints (Baseline, Follow-up 1, and Follow-up 2) using POMP scores.")

# Report model fit
cat("\n\nModel Fit:")
cat(paste0("\n  Chi-square: ", round(fit_indices["chisq"], 2), 
          " (df = ", round(fit_indices["df"]), 
          ", p = ", format(fit_indices["pvalue"], digits = 3), ")"))
cat(paste0("\n  CFI: ", round(fit_indices["cfi"], 3)))
cat(paste0("\n  TLI: ", round(fit_indices["tli"], 3)))
cat(paste0("\n  RMSEA: ", round(fit_indices["rmsea"], 3)))
cat(paste0("\n  SRMR: ", round(fit_indices["srmr"], 3)))

# Report correlations
cat("\n\nStandardized Correlations between Purpose and Happiness:")
cat(paste0("\n  Baseline: r = ", correlations_table$Correlation[1], " (p ", 
          ifelse(as.numeric(correlations_table$p_value[1]) < 0.001, "< 0.001", paste0("= ", correlations_table$p_value[1])), ")"))
cat(paste0("\n  Follow-up 1: r = ", correlations_table$Correlation[2], " (p ", 
          ifelse(as.numeric(correlations_table$p_value[2]) < 0.001, "< 0.001", paste0("= ", correlations_table$p_value[2])), ")"))
cat(paste0("\n  Follow-up 2: r = ", correlations_table$Correlation[3], " (p ", 
          ifelse(as.numeric(correlations_table$p_value[3]) < 0.001, "< 0.001", paste0("= ", correlations_table$p_value[3])), ")"))

cat("\n\nAnalysis completed successfully. Results and visualizations have been saved.")

# Save workspace for future reference
save.image("multisample_cfa_results.RData")


```

# Analysis 3:  Cross-lagged Panel Analysis (Causal Direction)

```{r}
#| echo: false
#| message: false
#| error: false
# Load required packages
library(lavaan)
library(tidyverse)
library(psych)  # for descriptive statistics

# Read the data
data <- read.csv("tmpPvHitems4LLM.csv")

# Create composite scores for happiness at each time point
# Using the subjective happiness scale (shs) items
data <- data %>%
  mutate(
    # Baseline happiness score (average of items)
    b_happiness = rowMeans(cbind(b_shs_gh_a, b_shs_rh_a, b_shs_ch_a, b_shs_ch_b_r), na.rm = TRUE)*100/7,
    
    # Follow-up 1 happiness score
    fu1_happiness = rowMeans(cbind(fu1_shs_gh_a, fu1_shs_rh_a, fu1_shs_ch_a, fu1_shs_ch_fu1_r), na.rm = TRUE)*100/7,
    
    # Follow-up 2 happiness score
    fu2_happiness = rowMeans(cbind(fu2_shs_gh_a, fu2_shs_rh_a, fu2_shs_ch_a, fu2_shs_ch_b_r), na.rm = TRUE)*100/7,
    
    # Baseline purpose score (average of items)
    b_purpose = rowMeans(cbind(b_bpurp_1, b_bpurp_2, b_bpurp_3, b_bpurp_4), na.rm = TRUE)*100/5,
    
    # Follow-up 1 purpose score
    fu1_purpose = rowMeans(cbind(fu1_bpurp_1, fu1_bpurp_2, fu1_bpurp_3, fu1_bpurp_4), na.rm = TRUE)*100/5,
    
    # Follow-up 2 purpose score
    fu2_purpose = rowMeans(cbind(fu2_bpurp_1, fu2_bpurp_2, fu2_bpurp_3, fu2_bpurp_4), na.rm = TRUE)*100/5
  )

# Check for missing data
missing_summary <- data %>%
  select(b_happiness, fu1_happiness, fu2_happiness, b_purpose, fu1_purpose, fu2_purpose) %>%
  summarise(across(everything(), ~sum(is.na(.))))
print("Missing values per variable:")
print(missing_summary)

# Check descriptive statistics
desc_stats <- describe(data[, c("b_happiness", "fu1_happiness", "fu2_happiness", 
                               "b_purpose", "fu1_purpose", "fu2_purpose")], skew = F, ranges = F)[,-1]
rownames(desc_stats) <- c("Baseline Happiness", "FU1 Happiness", "FU2 Happiness",
                          "Baseline Purpose", "FU1 Purpose", "FU2 Purpose")
print(desc_stats)

# Correlation matrix
cor_matrix <- cor(data[, c("b_happiness", "fu1_happiness", "fu2_happiness", 
                          "b_purpose", "fu1_purpose", "fu2_purpose")], 
                 use = "pairwise.complete.obs")
print("Correlation matrix:")
print(cor_matrix)

# Specify the cross-lagged panel model with simplex structure
# This follows the true cross-lagged panel design with adjacent time points
clpm_model <- '
  # Auto-regressive paths for happiness (simplex structure)
  fu1_happiness ~ a1*b_happiness
  fu2_happiness ~ a2*fu1_happiness
  
  # Auto-regressive paths for purpose (simplex structure)
  fu1_purpose ~ b1*b_purpose
  fu2_purpose ~ b2*fu1_purpose
  
  # Cross-lagged paths from happiness to purpose
  fu1_purpose ~ c1*b_happiness
  fu2_purpose ~ c2*fu1_happiness
  
  # Cross-lagged paths from purpose to happiness
  fu1_happiness ~ d1*b_purpose
  fu2_happiness ~ d2*fu1_purpose
  
  # Covariances between happiness and purpose at each time point
  b_happiness ~~ e1*b_purpose
  fu1_happiness ~~ e2*fu1_purpose
  fu2_happiness ~~ e3*fu2_purpose
  
  # Indirect effects of interest
  # Purpose → Happiness → Purpose pathway (baseline to fu2)
  p_h_p_indirect := d1*a2*b2 + b1*c2
  
  # Happiness → Purpose → Happiness pathway (baseline to fu2)
  h_p_h_indirect := c1*b2*d2 + a1*d2
'

# Fit the model
clpm_fit <- sem(clpm_model, data = data, missing = "fiml")

# Summary of the model with standardized estimates
summary(clpm_fit, standardized = TRUE, fit.measures = TRUE)

# Get parameter estimates in a data frame for easier inspection
param_est <- parameterEstimates(clpm_fit, standardized = TRUE)
print("Path coefficients (standardized):")
print(param_est[param_est$op == "~", c("lhs", "op", "rhs", "label", "est", "std.all", "pvalue")])

# Output key path estimates for interpretation
cat("\nAuto-regressive paths (stability):\n")
cat("Happiness (T1→T2):", param_est[param_est$label == "a1", "est"], "p =", param_est[param_est$label == "a1", "pvalue"], "\n")
cat("Happiness (T2→T3):", param_est[param_est$label == "a2", "est"], "p =", param_est[param_est$label == "a2", "pvalue"], "\n")
cat("Purpose (T1→T2):", param_est[param_est$label == "b1", "est"], "p =", param_est[param_est$label == "b1", "pvalue"], "\n")
cat("Purpose (T2→T3):", param_est[param_est$label == "b2", "est"], "p =", param_est[param_est$label == "b2", "pvalue"], "\n")

cat("\nCross-lagged effects:\n")
cat("Happiness→Purpose (T1→T2):", param_est[param_est$label == "c1", "est"], "p =", param_est[param_est$label == "c1", "pvalue"], "\n")
cat("Happiness→Purpose (T2→T3):", param_est[param_est$label == "c2", "est"], "p =", param_est[param_est$label == "c2", "pvalue"], "\n")
cat("Purpose→Happiness (T1→T2):", param_est[param_est$label == "d1", "est"], "p =", param_est[param_est$label == "d1", "pvalue"], "\n")
cat("Purpose→Happiness (T2→T3):", param_est[param_est$label == "d2", "est"], "p =", param_est[param_est$label == "d2", "pvalue"], "\n")

cat("\nIndirect effects:\n")
cat("Purpose→Happiness→Purpose:", param_est[param_est$label == "p_h_p_indirect", "est"], "p =", param_est[param_est$label == "p_h_p_indirect", "pvalue"], "\n")
cat("Happiness→Purpose→Happiness:", param_est[param_est$label == "h_p_h_indirect", "est"], "p =", param_est[param_est$label == "h_p_h_indirect", "pvalue"], "\n")

# Test for equality of cross-lagged effects
# This tests whether the cross-effects are equal in magnitude at each time point
equal_cross_model <- '
  # Auto-regressive paths for happiness (simplex structure)
  fu1_happiness ~ a1*b_happiness
  fu2_happiness ~ a2*fu1_happiness
  
  # Auto-regressive paths for purpose (simplex structure)
  fu1_purpose ~ b1*b_purpose
  fu2_purpose ~ b2*fu1_purpose
  
  # Constrained cross-lagged paths (equal across time points)
  fu1_purpose ~ c*b_happiness
  fu2_purpose ~ c*fu1_happiness
  
  # Constrained cross-lagged paths (equal across time points)
  fu1_happiness ~ d*b_purpose
  fu2_happiness ~ d*fu1_purpose
  
  # Test for difference between cross-effects
  cross_diff := c - d
  
  # Covariances between happiness and purpose at each time point
  b_happiness ~~ b_purpose
  fu1_happiness ~~ fu1_purpose
  fu2_happiness ~~ fu2_purpose
'

equal_cross_fit <- sem(equal_cross_model, data = data, missing = "fiml")
summary(equal_cross_fit, standardized = TRUE, fit.measures = TRUE)

# Compare models to test if constraining cross-effects worsens fit
cat("\nModel comparison - testing equality of cross-lagged effects across time:\n")
anova_result <- anova(clpm_fit, equal_cross_fit)
print(anova_result)

# Alternative model testing bi-directional equality
# This tests whether happiness→purpose = purpose→happiness
bidirectional_equal_model <- '
  # Auto-regressive paths for happiness (simplex structure)
  fu1_happiness ~ a1*b_happiness
  fu2_happiness ~ a2*fu1_happiness
  
  # Auto-regressive paths for purpose (simplex structure)
  fu1_purpose ~ b1*b_purpose
  fu2_purpose ~ b2*fu1_purpose
  
  # Cross-lagged paths constrained to be equal bidirectionally at T1→T2
  fu1_purpose ~ c*b_happiness
  fu1_happiness ~ c*b_purpose
  
  # Cross-lagged paths constrained to be equal bidirectionally at T2→T3
  fu2_purpose ~ d*fu1_happiness
  fu2_happiness ~ d*fu1_purpose
  
  # Covariances between happiness and purpose at each time point
  b_happiness ~~ b_purpose
  fu1_happiness ~~ fu1_purpose
  fu2_happiness ~~ fu2_purpose
'

bidirectional_fit <- sem(bidirectional_equal_model, data = data, missing = "fiml")
summary(bidirectional_fit, standardized = TRUE, fit.measures = TRUE)

# Compare models to test if bidirectional equality constraints worsen fit
cat("\nModel comparison - testing bidirectional equality of cross-lagged effects:\n")
anova_result2 <- anova(clpm_fit, bidirectional_fit)
print(anova_result2)

# Calculate R-squared for each endogenous variable
r2_values <- inspect(clpm_fit, "r2")
cat("\nVariance explained (R-squared):\n")
print(r2_values)

# Optional: visualize the model if semPlot is available
# Uncomment these lines if you want a diagram
# if (requireNamespace("semPlot", quietly = TRUE)) {
#   library(semPlot)
#   semPaths(clpm_fit, what = "std", edge.label.cex = 0.7,
#            style = "ram", layout = "tree2",
#            intercepts = FALSE, residuals = FALSE,
#            edge.color = "black",
#            nodeLabels = c("B_Hap", "FU1_Hap", "FU2_Hap",
#                           "B_Purp", "FU1_Purp", "FU2_Purp"))
# }



```



# Analysis 3:  Quantile Regression (Deeper Look into the Relationship)

```{r}
#| echo: false
#| message: false
#| error: false

# Quantile Regression Analysis of Purpose and Happiness
# Based on Killingsworth et al. (2023) approach

# Load required packages
library(tidyverse)
library(quantreg)  # For quantile regression
library(ggplot2)   # For visualization
library(knitr)     # For table outputs
library(kableExtra)
library(data.table)

# Read the data
data <- read.csv("tmpPvHitems4LLM.csv")

# Create composite scores for happiness and purpose at each time point
# Using the code from your cross-lagged-panel-model.r
data <- data %>%
  mutate(
    # Baseline happiness score (average of items)
    b_happiness = rowMeans(cbind(b_shs_gh_a, b_shs_rh_a, b_shs_ch_a, b_shs_ch_b_r), na.rm = TRUE)*100/7,
    
    # Follow-up 1 happiness score
    fu1_happiness = rowMeans(cbind(fu1_shs_gh_a, fu1_shs_rh_a, fu1_shs_ch_a, fu1_shs_ch_fu1_r), na.rm = TRUE)*100/7,
    
    # Follow-up 2 happiness score
    fu2_happiness = rowMeans(cbind(fu2_shs_gh_a, fu2_shs_rh_a, fu2_shs_ch_a, fu2_shs_ch_b_r), na.rm = TRUE)*100/7,
    
    # Baseline purpose score (average of items)
    b_purpose = rowMeans(cbind(b_bpurp_1, b_bpurp_2, b_bpurp_3, b_bpurp_4), na.rm = TRUE)*100/5,
    
    # Follow-up 1 purpose score
    fu1_purpose = rowMeans(cbind(fu1_bpurp_1, fu1_bpurp_2, fu1_bpurp_3, fu1_bpurp_4), na.rm = TRUE)*100/5,
    
    # Follow-up 2 purpose score
    fu2_purpose = rowMeans(cbind(fu2_bpurp_1, fu2_bpurp_2, fu2_bpurp_3, fu2_bpurp_4), na.rm = TRUE)*100/5
  )

# Function to run quantile regression for a specific timepoint
run_quantile_regression <- function(data, purpose_var, happiness_var, quantiles = c(0.15, 0.30, 0.50, 0.70, 0.85)) {
  results <- list()
  
  # Create a binned version of purpose for visualization
  # Create custom breaks to avoid the "breaks are not unique" error
  purpose_values <- data[[purpose_var]][!is.na(data[[purpose_var]])]
  min_val <- min(purpose_values, na.rm = TRUE)
  max_val <- max(purpose_values, na.rm = TRUE)
  range_val <- max_val - min_val
  
  # Create 10 equally spaced breaks
  custom_breaks <- seq(min_val, max_val, length.out = 11)
  
  data_with_binned_purpose <- data %>%
    mutate(purpose_bin = cut(get(purpose_var), 
                            breaks = custom_breaks,
                            include.lowest = TRUE,
                            labels = FALSE)) %>%
    group_by(purpose_bin) %>%
    mutate(purpose_bin_value = mean(get(purpose_var), na.rm = TRUE)) %>%
    ungroup()
  
  # Run quantile regression for each specified quantile
  for (q in quantiles) {
    model <- rq(formula(paste(happiness_var, "~", purpose_var)), 
               tau = q, 
               data = data)
    
    # Get summary using nid method which is more robust
    model_summary <- summary(model, se = "nid")
    
    results[[as.character(q)]] <- list(
      model = model,
      coef = coef(model),
      summary = model_summary
    )
  }
  
  # Create a dataframe for plotting
  plot_data <- data_with_binned_purpose %>%
    select(purpose_bin_value, !!sym(happiness_var)) %>%
    filter(!is.na(purpose_bin_value), !is.na(!!sym(happiness_var)))
  
  list(
    results = results,
    plot_data = plot_data,
    binned_data = data_with_binned_purpose
  )
}

# Run quantile regression for each timepoint
b_qr <- run_quantile_regression(data, "b_purpose", "b_happiness")
fu1_qr <- run_quantile_regression(data, "fu1_purpose", "fu1_happiness")
fu2_qr <- run_quantile_regression(data, "fu2_purpose", "fu2_happiness")

# Create a summary table of quantile regression slopes
create_slope_table <- function(qr_results, timepoint) {
  # Create a data frame with consistent columns
  slopes_df <- data.frame(
    Quantile = numeric(),
    Slope = numeric(),
    t_value = numeric(),
    p_value = numeric(),
    Timepoint = character(),
    Significant = character(),
    stringsAsFactors = FALSE
  )
  
  # Add data for each quantile
  for (q in names(qr_results$results)) {
    model <- qr_results$results[[q]]
    
    # Use nid method for standard errors which is more reliable
    model_summary <- summary(model$model, se = "nid")
    
    # Extract coefficient info safely
    coef_index <- 2  # Index for the purpose variable coefficient
    slope <- model$coef[2]  # The slope is the coefficient for the purpose variable
    
    # Get t-value and p-value more safely
    t_value <- NA
    p_value <- NA
    
    if (!is.null(model_summary$coefficients) && 
        nrow(model_summary$coefficients) >= 2 && 
        ncol(model_summary$coefficients) >= 3) {
      
      # Standard format with t-values and p-values
      t_value <- model_summary$coefficients[2, 3]
      
      if (ncol(model_summary$coefficients) >= 4) {
        p_value <- model_summary$coefficients[2, 4]
      }
    }
    
    # Add row to the data frame
    new_row <- data.frame(
      Quantile = as.numeric(q),
      Slope = slope,
      t_value = t_value,
      p_value = p_value,
      Timepoint = timepoint,
      Significant = ifelse(!is.na(p_value) & p_value < 0.05, "*", ""),
      stringsAsFactors = FALSE
    )
    
    slopes_df <- rbind(slopes_df, new_row)
  }
  
  return(slopes_df)
}

b_slopes <- create_slope_table(b_qr, "Baseline")
fu1_slopes <- create_slope_table(fu1_qr, "Follow-up 1")
fu2_slopes <- create_slope_table(fu2_qr, "Follow-up 2")

# Combine all slope tables
all_slopes <- rbind(b_slopes, fu1_slopes, fu2_slopes)
all_slopes <- all_slopes[order(all_slopes$Timepoint, all_slopes$Quantile),]

# Format the table for display
formatted_table <- all_slopes %>%
  mutate(
    Quantile = paste0(Quantile * 100, "th"),
    Slope = sprintf("%.2f", Slope),
    t_value = sprintf("%.2f", t_value),
    p_value = sprintf("%.3f", p_value)
  )

# Print the formatted table
kable(formatted_table, 
      caption = "Quantile Regression Slopes: Happiness Regressed on Purpose",
      col.names = c("Quantile", "Slope", "t-value", "p-value", "Timepoint", "Significant")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE) %>%
  column_spec(6, bold = TRUE)  # Make the significance column stand out

# Create a visualization similar to Figure 2 in Killingsworth et al. (2023)
# Function to create the plot for a specific timepoint
create_quantile_plot <- function(qr_results, purpose_var, happiness_var, timepoint) {
  # Get the binned data
  binned_data <- qr_results$binned_data
  
  # Calculate actual quantiles for each purpose bin
  quantile_data <- binned_data %>%
    group_by(purpose_bin_value) %>%
    summarise(
      q15 = quantile(get(happiness_var), 0.15, na.rm = TRUE),
      q30 = quantile(get(happiness_var), 0.30, na.rm = TRUE),
      q50 = quantile(get(happiness_var), 0.50, na.rm = TRUE),
      q70 = quantile(get(happiness_var), 0.70, na.rm = TRUE),
      q85 = quantile(get(happiness_var), 0.85, na.rm = TRUE),
      n = n()
    ) %>%
    filter(n >= 5)  # Only include bins with sufficient data
  
  # Create plot
  p <- ggplot() +
    # 15th percentile
    geom_point(data = quantile_data, aes(x = purpose_bin_value, y = q15), color = "blue", size = 3, alpha = 0.7) +
    geom_smooth(data = quantile_data, aes(x = purpose_bin_value, y = q15), method = "lm", color = "blue", se = FALSE) +
    
    # 30th percentile
    geom_point(data = quantile_data, aes(x = purpose_bin_value, y = q30), color = "green", size = 3, alpha = 0.7) +
    geom_smooth(data = quantile_data, aes(x = purpose_bin_value, y = q30), method = "lm", color = "green", se = FALSE) +
    
    # 50th percentile (median)
    geom_point(data = quantile_data, aes(x = purpose_bin_value, y = q50), color = "black", size = 3, alpha = 0.7) +
    geom_smooth(data = quantile_data, aes(x = purpose_bin_value, y = q50), method = "lm", color = "black", se = FALSE) +
    
    # 70th percentile
    geom_point(data = quantile_data, aes(x = purpose_bin_value, y = q70), color = "orange", size = 3, alpha = 0.7) +
    geom_smooth(data = quantile_data, aes(x = purpose_bin_value, y = q70), method = "lm", color = "orange", se = FALSE) +
    
    # 85th percentile
    geom_point(data = quantile_data, aes(x = purpose_bin_value, y = q85), color = "red", size = 3, alpha = 0.7) +
    geom_smooth(data = quantile_data, aes(x = purpose_bin_value, y = q85), method = "lm", color = "red", se = FALSE) +
    
    # Labels and theme
    labs(
      title = paste("Happiness by Purpose in Life:", timepoint),
      subtitle = "Showing the 15th, 30th, 50th, 70th, and 85th percentiles of happiness",
      x = "Purpose in Life Score",
      y = "Happiness Score"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5),
      legend.position = "bottom"
    ) +
    # Add annotations for the quantiles
    annotate("text", x = min(quantile_data$purpose_bin_value, na.rm = TRUE), 
             y = max(quantile_data$q85, na.rm = TRUE), 
             label = "85th percentile", hjust = -0.1, color = "red") +
    annotate("text", x = min(quantile_data$purpose_bin_value, na.rm = TRUE), 
             y = max(quantile_data$q70, na.rm = TRUE), 
             label = "70th percentile", hjust = -0.1, color = "orange") +
    annotate("text", x = min(quantile_data$purpose_bin_value, na.rm = TRUE), 
             y = max(quantile_data$q50, na.rm = TRUE), 
             label = "50th percentile", hjust = -0.1, color = "black") +
    annotate("text", x = min(quantile_data$purpose_bin_value, na.rm = TRUE), 
             y = max(quantile_data$q30, na.rm = TRUE), 
             label = "30th percentile", hjust = -0.1, color = "green") +
    annotate("text", x = min(quantile_data$purpose_bin_value, na.rm = TRUE), 
             y = max(quantile_data$q15, na.rm = TRUE), 
             label = "15th percentile", hjust = -0.1, color = "blue")
  
  return(p)
}

# Create the plots for each timepoint
b_plot <- create_quantile_plot(b_qr, "b_purpose", "b_happiness", "Baseline")
fu1_plot <- create_quantile_plot(fu1_qr, "fu1_purpose", "fu1_happiness", "Follow-up 1")
fu2_plot <- create_quantile_plot(fu2_qr, "fu2_purpose", "fu2_happiness", "Follow-up 2")

# Print the plots
print(b_plot)
print(fu1_plot)
print(fu2_plot)

# Piecewise Quantile Regression Analysis
# Function to run piecewise quantile regression with a breakpoint
run_piecewise_qr <- function(data, purpose_var, happiness_var, 
                             breakpoint = NULL, quantiles = c(0.15, 0.30, 0.50, 0.70, 0.85)) {
  
  # If breakpoint is NULL, determine it using the median
  if (is.null(breakpoint)) {
    breakpoint <- median(data[[purpose_var]], na.rm = TRUE)
  }
  
  # Create variables for piecewise regression
  data <- data %>%
    mutate(
      purpose_low = ifelse(get(purpose_var) <= breakpoint, get(purpose_var), breakpoint),
      purpose_high = ifelse(get(purpose_var) > breakpoint, get(purpose_var) - breakpoint, 0)
    )
  
  results <- list()
  
  # Run quantile regression for each specified quantile
  for (q in quantiles) {
    model <- rq(formula(paste(happiness_var, "~ purpose_low + purpose_high")), 
                tau = q, 
                data = data)
    
    # Test if the slopes are different
    low_slope <- coef(model)["purpose_low"]
    high_slope <- coef(model)["purpose_high"]
    
    # Construct a test for difference in slopes
    wald_test <- summary(model, se = "boot", R = 1000)
    
    results[[as.character(q)]] <- list(
      model = model,
      low_slope = low_slope,
      high_slope = high_slope,
      p_value = wald_test$coefficients["purpose_high", 4],
      breakpoint = breakpoint
    )
  }
  
  return(results)
}

# Run piecewise quantile regression for each timepoint
# Let's determine breakpoints at the median of purpose scores
b_breakpoint <- median(data$b_purpose, na.rm = TRUE)
fu1_breakpoint <- median(data$fu1_purpose, na.rm = TRUE)
fu2_breakpoint <- median(data$fu2_purpose, na.rm = TRUE)

b_piecewise <- run_piecewise_qr(data, "b_purpose", "b_happiness", b_breakpoint)
fu1_piecewise <- run_piecewise_qr(data, "fu1_purpose", "fu1_happiness", fu1_breakpoint)
fu2_piecewise <- run_piecewise_qr(data, "fu2_purpose", "fu2_happiness", fu2_breakpoint)

# Create a summary table for piecewise regression results
create_piecewise_table <- function(piecewise_results, timepoint) {
  result_df <- data.frame(
    Quantile = numeric(),
    Low_Slope = numeric(),
    High_Slope = numeric(),
    Slope_Diff = numeric(),
    p_value = numeric(),
    Breakpoint = numeric(),
    Timepoint = character(),
    stringsAsFactors = FALSE
  )
  
  for (q in names(piecewise_results)) {
    result <- piecewise_results[[q]]
    result_df <- rbind(result_df, data.frame(
      Quantile = as.numeric(q),
      Low_Slope = result$low_slope,
      High_Slope = result$high_slope,
      Slope_Diff = result$high_slope - result$low_slope,
      p_value = result$p_value,
      Breakpoint = result$breakpoint,
      Timepoint = timepoint
    ))
  }
  
  return(result_df)
}

b_piecewise_table <- create_piecewise_table(b_piecewise, "Baseline")
fu1_piecewise_table <- create_piecewise_table(fu1_piecewise, "Follow-up 1")
fu2_piecewise_table <- create_piecewise_table(fu2_piecewise, "Follow-up 2")

# Combine all piecewise tables
all_piecewise <- rbind(b_piecewise_table, fu1_piecewise_table, fu2_piecewise_table)
all_piecewise <- all_piecewise[order(all_piecewise$Timepoint, all_piecewise$Quantile),]

# Format the piecewise table for display
formatted_piecewise <- all_piecewise %>%
  mutate(
    Quantile = paste0(Quantile * 100, "th"),
    Low_Slope = ifelse(is.na(Low_Slope), "NA", sprintf("%.2f", Low_Slope)),
    High_Slope = ifelse(is.na(High_Slope), "NA", sprintf("%.2f", High_Slope)),
    Slope_Diff = ifelse(is.na(Slope_Diff), "NA", sprintf("%.2f", Slope_Diff)),
    p_value = ifelse(is.na(p_value), "NA", sprintf("%.3f", p_value)),
    Significant = ifelse(!is.na(p_value) & p_value < 0.05, "*", "")
  )

# Print the formatted piecewise table
kable(formatted_piecewise, 
      caption = "Piecewise Quantile Regression: Slopes Below and Above the Breakpoint",
      col.names = c("Quantile", "Low Slope", "High Slope", "Diff", "p-value", "Breakpoint", "Timepoint", "Significant")) %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = FALSE)

# Additional analysis: Compare the relationship across different timepoints
# This can help understand how the relationship evolves over time

# Create a comparative plot for the median (50th percentile)
create_comparative_plot <- function(data) {
  # Create custom breaks for each timepoint to avoid "breaks are not unique" error
  b_purpose_values <- data$b_purpose[!is.na(data$b_purpose)]
  b_min <- min(b_purpose_values, na.rm = TRUE)
  b_max <- max(b_purpose_values, na.rm = TRUE)
  b_breaks <- seq(b_min, b_max, length.out = 11)
  
  fu1_purpose_values <- data$fu1_purpose[!is.na(data$fu1_purpose)]
  fu1_min <- min(fu1_purpose_values, na.rm = TRUE)
  fu1_max <- max(fu1_purpose_values, na.rm = TRUE)
  fu1_breaks <- seq(fu1_min, fu1_max, length.out = 11)
  
  fu2_purpose_values <- data$fu2_purpose[!is.na(data$fu2_purpose)]
  fu2_min <- min(fu2_purpose_values, na.rm = TRUE)
  fu2_max <- max(fu2_purpose_values, na.rm = TRUE)
  fu2_breaks <- seq(fu2_min, fu2_max, length.out = 11)
  
  # Calculate median happiness for each purpose bin at each timepoint
  median_data <- data %>%
    mutate(
      b_purpose_bin = cut(b_purpose, breaks = b_breaks, include.lowest = TRUE, labels = FALSE),
      fu1_purpose_bin = cut(fu1_purpose, breaks = fu1_breaks, include.lowest = TRUE, labels = FALSE),
      fu2_purpose_bin = cut(fu2_purpose, breaks = fu2_breaks, include.lowest = TRUE, labels = FALSE)
    ) %>%
    group_by(b_purpose_bin) %>%
    mutate(b_purpose_value = mean(b_purpose, na.rm = TRUE),
           b_happiness_median = median(b_happiness, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(fu1_purpose_bin) %>%
    mutate(fu1_purpose_value = mean(fu1_purpose, na.rm = TRUE),
           fu1_happiness_median = median(fu1_happiness, na.rm = TRUE)) %>%
    ungroup() %>%
    group_by(fu2_purpose_bin) %>%
    mutate(fu2_purpose_value = mean(fu2_purpose, na.rm = TRUE),
           fu2_happiness_median = median(fu2_happiness, na.rm = TRUE)) %>%
    ungroup()
  
  # Create a long format dataset for plotting
  b_data <- median_data %>%
    select(purpose = b_purpose_value, happiness = b_happiness_median) %>%
    mutate(timepoint = "Baseline") %>%
    distinct(purpose, happiness, timepoint)
  
  fu1_data <- median_data %>%
    select(purpose = fu1_purpose_value, happiness = fu1_happiness_median) %>%
    mutate(timepoint = "Follow-up 1") %>%
    distinct(purpose, happiness, timepoint)
  
  fu2_data <- median_data %>%
    select(purpose = fu2_purpose_value, happiness = fu2_happiness_median) %>%
    mutate(timepoint = "Follow-up 2") %>%
    distinct(purpose, happiness, timepoint)
  
  plot_data <- rbind(b_data, fu1_data, fu2_data) %>%
    filter(!is.na(purpose), !is.na(happiness))
  
  # Create the plot
  p <- ggplot(plot_data, aes(x = purpose, y = happiness, color = timepoint)) +
    geom_point(size = 3, alpha = 0.7) +
    geom_smooth(method = "lm", se = FALSE) +
    labs(
      title = "Relationship Between Purpose and Happiness Across Timepoints",
      subtitle = "Showing median happiness values",
      x = "Purpose in Life Score",
      y = "Happiness Score",
      color = "Timepoint"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(hjust = 0.5, face = "bold"),
      plot.subtitle = element_text(hjust = 0.5),
      legend.position = "bottom"
    )
  
  return(p)
}

# Create the comparative plot
comparative_plot <- create_comparative_plot(data)
print(comparative_plot)

# Save the results and plots
# Uncomment and run these lines to save the outputs
# ggsave("baseline_quantile_plot.png", b_plot, width = 10, height = 8)
# ggsave("followup1_quantile_plot.png", fu1_plot, width = 10, height = 8)
# ggsave("followup2_quantile_plot.png", fu2_plot, width = 10, height = 8)
# ggsave("comparative_plot.png", comparative_plot, width = 10, height = 8)
# write.csv(all_slopes, "quantile_regression_slopes.csv", row.names = FALSE)
# write.csv(all_piecewise, "piecewise_quantile_regression.csv", row.names = FALSE)

# Print a summary of findings
cat("\n----- Summary of Quantile Regression Analysis -----\n")
cat("This analysis examines the relationship between purpose and happiness at different\n")
cat("quantiles of the happiness distribution, similar to the approach by Killingsworth et al. (2023).\n\n")

cat("Key findings:\n")
cat("1. Slope patterns across quantiles: ")
for (timepoint in unique(all_slopes$Timepoint)) {
  timepoint_slopes <- all_slopes[all_slopes$Timepoint == timepoint,]
  min_slope <- min(as.numeric(timepoint_slopes$Slope))
  max_slope <- max(as.numeric(timepoint_slopes$Slope))
  cat(sprintf("\n   - %s: Slopes range from %.2f to %.2f", timepoint, min_slope, max_slope))
}

cat("\n\n2. Piecewise regression results: ")
for (timepoint in unique(all_piecewise$Timepoint)) {
  timepoint_pw <- all_piecewise[all_piecewise$Timepoint == timepoint,]
  significant_diff <- any(as.numeric(gsub("0\\.", ".", timepoint_pw$p_value)) < 0.05)
  if (significant_diff) {
    cat(sprintf("\n   - %s: Significant differences in slopes around the breakpoint", timepoint))
  } else {
    cat(sprintf("\n   - %s: No significant differences in slopes around the breakpoint", timepoint))
  }
}

cat("\n\n3. Comparative analysis across timepoints:\n")
cat("   - The relationship between purpose and happiness ")
# This will be completed based on the results



```




